# CLIP PubMedVision

In this project, the objective was to investigate the potential of (medical) image-text data when fine-tuning CLIP for image classification, in absence of labeled data. The project was done as part of the course [TDDE09 Natural Language Processing](https://liu-nlp.ai/tdde09/).

The details of the project and my personal learnings are described in [this short paper](paper.pdf).

Credit is due to my fellow project mates, who also contributed to the project: Johan von Axelson, Gabriel BÃ¼low, Abbas Alubeid, Karl Duckert Karlsson and Gor Durgaryan.
